{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "891bea2e-2ff6-4d64-839e-b7b24268a5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib_inline import backend_inline\n",
    "backend_inline.set_matplotlib_formats('svg') # 展示高清图，在 Jupyter Notebook 中设置 matplotlib 图形的输出格式为 SVG 格式\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from scipy.signal import savgol_filter\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split as TTS\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import random_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, confusion_matrix, classification_report\n",
    "\n",
    "import random\n",
    "seed = 0\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a354f98a-dedb-4a36-9bbc-6acf8144f3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11913"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 检测系统是否支持 CUDA，即是否有 NVIDIA GPU 可用\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# 加载数据\n",
    "data = pd.read_csv(r\"D:\\向航\\Jupyter_project\\02_HSNI data classification\\Final_Model\\data_cz_test_ANN\\data_33_lithology_train.csv\",encoding='utf-8') #encoding='GBK',防止中文乱码\n",
    "\n",
    "# 数据预处理\n",
    "X_origin = data.iloc[:,1:-1]\n",
    "y_origin = data.iloc[:,-1]\n",
    "X_SG = savgol_filter(X_origin, 5, 2)\n",
    "Label = LabelEncoder().fit_transform(y_origin)\n",
    "data.iloc[:,1:-1] = X_SG\n",
    "data.iloc[:, -1] = Label\n",
    "X = data.iloc[:,1:-1]\n",
    "y = data.iloc[:,-1]\n",
    "X.shape, y.shape\n",
    "\n",
    "# 降维\n",
    "X_dr = PCA(29).fit_transform(X)\n",
    "\n",
    "# 转换为 torch 中的张量格式\n",
    "X_tensor = torch.tensor(X_dr, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "# 假设 device 已经设置为 \"cuda\" 或 \"cpu\"\n",
    "X_tensor = X_tensor.to(device)\n",
    "y_tensor = y_tensor.to(device)\n",
    "\n",
    "# 创建整个数据集的 TensorDataset\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "\n",
    "# 创建 DataLoader 对象\n",
    "data_loader = DataLoader(dataset, batch_size=64, shuffle=True)  # 可以调整 batch_size 和 shuffle\n",
    "\n",
    "# 获取数据集的大小\n",
    "dataset_size = len(dataset)\n",
    "\n",
    "dataset_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "986bebdc-baa2-410a-91cb-7464ad847ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Original_Label  Encoded_Label\n",
      "0          01_辉绿岩              0\n",
      "1          02_斜长岩              1\n",
      "2          03_正长岩              2\n",
      "3        05_辉石闪长岩              3\n",
      "4         07_花岗斑岩              4\n",
      "5          09_橄榄岩              5\n",
      "6         10_闪长玢岩              6\n",
      "7        11_粗粒花岗岩              7\n",
      "8        12_斑状花岗岩              8\n",
      "9        13_斜长花岗岩              9\n",
      "10       17_角砾凝灰岩             10\n",
      "11        26_紫色页岩             11\n",
      "12        28_炭质页岩             12\n",
      "13        31_泥质灰岩             13\n",
      "14       33_泥晶石灰岩             14\n",
      "15        37_石英砾岩             15\n",
      "16       38_复成份砾岩             16\n",
      "17        41_石英砂岩             17\n",
      "18         42_细砂岩             18\n",
      "19      43_高岭石粘土岩             19\n",
      "20      44_蒙脱石粘土岩             20\n",
      "21      45_伊利石粘土岩             21\n",
      "22        49_石英岩②             22\n",
      "23         51_云英岩             23\n",
      "24       55_粗晶大理岩             24\n",
      "25       56_雪白大理岩             25\n",
      "26       58_花岗片麻岩             26\n",
      "27       59_绿泥石片岩             27\n",
      "28     60_含榴白云母片岩             28\n",
      "29      63_云母石英片岩             29\n",
      "30       64_十字石片岩             30\n",
      "31         66_蛇纹岩             31\n",
      "32     67_石榴子石矽卡岩             32\n"
     ]
    }
   ],
   "source": [
    "# 初始化 LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# 对原始标签进行拟合\n",
    "label_encoder.fit(y_origin)\n",
    "\n",
    "# 创建一个 DataFrame 来展示原始标签与转换后标签的对应关系\n",
    "label_mapping_df = pd.DataFrame({\n",
    "    'Original_Label': label_encoder.classes_,\n",
    "    'Encoded_Label': label_encoder.transform(label_encoder.classes_)\n",
    "})\n",
    "\n",
    "# 显示表格\n",
    "print(label_mapping_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc70d98a-9b68-44fe-8e57-268b090e920d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNN(\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=29, out_features=170, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.16, inplace=False)\n",
       "    (3): Linear(in_features=170, out_features=241, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.16, inplace=False)\n",
       "    (6): Linear(in_features=241, out_features=97, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Dropout(p=0.16, inplace=False)\n",
       "    (9): Linear(in_features=97, out_features=177, bias=True)\n",
       "    (10): ReLU()\n",
       "    (11): Dropout(p=0.16, inplace=False)\n",
       "    (12): Linear(in_features=177, out_features=164, bias=True)\n",
       "    (13): ReLU()\n",
       "    (14): Dropout(p=0.16, inplace=False)\n",
       "    (15): Linear(in_features=164, out_features=34, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 搭建网络\n",
    "class DNN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes, hidden_layer_sizes, dropout_prob):\n",
    "        ''' 搭建神经网络各层 '''\n",
    "        super(DNN, self).__init__()\n",
    "\n",
    "        self.hidden_layer_sizes = hidden_layer_sizes  # 调整隐藏层尺寸\n",
    "        self.dropout_prob = dropout_prob  # 调整 dropout 概率\n",
    "\n",
    "        layers = []\n",
    "        prev_layer_size = input_size\n",
    "\n",
    "        for layer_size in self.hidden_layer_sizes:\n",
    "            layers.append(nn.Linear(prev_layer_size, layer_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(self.dropout_prob))\n",
    "            prev_layer_size = layer_size\n",
    "\n",
    "        layers.append(nn.Linear(prev_layer_size, num_classes))\n",
    "\n",
    "        self.net = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ''' 前向传播 '''\n",
    "        y = self.net(x) # x 即输入数据\n",
    "        return y # y 即输出数据\n",
    "\n",
    "# 贝叶斯优化超参数\n",
    "num_classes = 33\n",
    "input_size = X_tensor.shape[1]\n",
    "hidden_layer_sizes = [170, 241, 97, 177, 164]\n",
    "dropout_prob = 0.16\n",
    "\n",
    "# 创建模型实例\n",
    "model = DNN(input_size, num_classes, hidden_layer_sizes, dropout_prob)\n",
    "model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfdfd3aa-0d49-41c6-8191-f84782ba95e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15] - Loss: 1.6022, Cumulative Avg Loss: 1.6022, Accuracy: 0.4656\n",
      "Epoch [2/15] - Loss: 0.4246, Cumulative Avg Loss: 1.0134, Accuracy: 0.8498\n",
      "Epoch [3/15] - Loss: 0.2327, Cumulative Avg Loss: 0.7532, Accuracy: 0.9216\n",
      "Epoch [4/15] - Loss: 0.1410, Cumulative Avg Loss: 0.6001, Accuracy: 0.9559\n",
      "Epoch [5/15] - Loss: 0.1124, Cumulative Avg Loss: 0.5026, Accuracy: 0.9655\n",
      "Epoch [6/15] - Loss: 0.1156, Cumulative Avg Loss: 0.4381, Accuracy: 0.9644\n",
      "Epoch [7/15] - Loss: 0.0951, Cumulative Avg Loss: 0.3891, Accuracy: 0.9752\n",
      "Epoch [8/15] - Loss: 0.0727, Cumulative Avg Loss: 0.3496, Accuracy: 0.9798\n",
      "Epoch [9/15] - Loss: 0.0617, Cumulative Avg Loss: 0.3176, Accuracy: 0.9820\n",
      "Epoch [10/15] - Loss: 0.0534, Cumulative Avg Loss: 0.2912, Accuracy: 0.9846\n",
      "Epoch [11/15] - Loss: 0.0596, Cumulative Avg Loss: 0.2701, Accuracy: 0.9834\n",
      "Epoch [12/15] - Loss: 0.0876, Cumulative Avg Loss: 0.2549, Accuracy: 0.9793\n",
      "Epoch [13/15] - Loss: 0.0368, Cumulative Avg Loss: 0.2381, Accuracy: 0.9905\n",
      "Epoch [14/15] - Loss: 0.0517, Cumulative Avg Loss: 0.2248, Accuracy: 0.9878\n",
      "Epoch [15/15] - Loss: 0.0462, Cumulative Avg Loss: 0.2129, Accuracy: 0.9876\n"
     ]
    }
   ],
   "source": [
    "# 训练\n",
    "loss_fn = nn.CrossEntropyLoss(reduction='mean') # 对所有样本的损失求平均，得到一个标量\n",
    "learning_rate = 0.0028690154931344\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 15\n",
    "accuracies = [] # 记录准确率变化的列表\n",
    "losses = [] # 记录损失函数变化的列表\n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    batch_loss = 0\n",
    "    \n",
    "    for (x, y) in data_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        Pred = model(x)\n",
    "        _, Pred_classes = torch.max(Pred, dim=1)\n",
    "        total_correct += torch.sum(Pred_classes == y)\n",
    "        total_samples += y.size(0)\n",
    "        loss = loss_fn(Pred, y)\n",
    "        batch_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    epoch_loss = batch_loss / len(data_loader)\n",
    "    epoch_accuracy = total_correct / total_samples\n",
    "    accuracies.append(epoch_accuracy.item())\n",
    "    losses.append(epoch_loss)\n",
    "\n",
    "    # 打印当前 epoch 的损失和累计平均损失\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] - Loss: {epoch_loss:.4f}, Cumulative Avg Loss: {sum(losses)/(epoch+1):.4f}, Accuracy: {epoch_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70207b6e-cca4-4b0b-90c3-f5cf724f19b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8 11 32 15 16  8 29 15 22 29 32  0 29  8 15 23 26 20 29 28 29 16 15  7\n",
      " 28 16 29 29 15 29 16 23 30 29 32 28 17 17 17 30 17 28 15 28 30 17 28 30\n",
      "  2 24 17 28 28 28 17 30 28 17 30 17 28 17 28 29 29 29 26 17 30  7 17 29\n",
      " 17 22 28 22 13  2 17 17 17 30 17 30  0]\n",
      "    Predicted_Label  Count\n",
      "11                0      2\n",
      "12                2      2\n",
      "13                7      2\n",
      "7                 8      3\n",
      "16               11      1\n",
      "15               13      1\n",
      "4                15      6\n",
      "5                16      4\n",
      "0                17     17\n",
      "17               20      1\n",
      "8                22      3\n",
      "9                23      2\n",
      "14               24      1\n",
      "10               26      2\n",
      "2                28     13\n",
      "1                29     13\n",
      "3                30      9\n",
      "6                32      3\n"
     ]
    }
   ],
   "source": [
    "# 加载新数据\n",
    "test_data = pd.read_csv(r\"D:\\向航\\Jupyter_project\\02_HSNI data classification\\Final_Model\\data_cz_test_ANN\\data_cz_test_2.csv\", encoding='utf-8')\n",
    "\n",
    "# 应用相同的数据预处理\n",
    "X_test_origin = test_data.iloc[:, 1:]  # 假设第一列是索引或非特征列\n",
    "X_test_SG = savgol_filter(X_test_origin, 5, 2)\n",
    "\n",
    "# 降维\n",
    "X_test_dr = PCA(29).fit_transform(X_test_SG)\n",
    "\n",
    "# 转换为 torch 中的张量格式\n",
    "X_test_tensor = torch.tensor(X_test_dr, dtype=torch.float32)\n",
    "X_test_tensor = X_test_tensor.to(device)\n",
    "\n",
    "# 使用模型进行预测\n",
    "model.eval()  # 将模型设置为评估模式\n",
    "with torch.no_grad():\n",
    "    test_pred = model(X_test_tensor)\n",
    "    _, test_pred_classes = torch.max(test_pred, dim=1)\n",
    "\n",
    "# 输出预测结果\n",
    "predicted_labels = test_pred_classes.cpu().numpy()\n",
    "print(predicted_labels)\n",
    "\n",
    "# 创建一个 DataFrame 来保存预测标签\n",
    "predicted_df = pd.DataFrame(predicted_labels, columns=['Predicted_Label'])\n",
    "\n",
    "# 计算每个预测标签的出现次数\n",
    "label_counts = predicted_df['Predicted_Label'].value_counts()\n",
    "\n",
    "# 将结果转换为 DataFrame 并重置索引\n",
    "label_counts_df = label_counts.reset_index()\n",
    "label_counts_df.columns = ['Predicted_Label', 'Count']\n",
    "\n",
    "# 对 DataFrame 按标签进行排序（从小到大）\n",
    "sorted_label_counts_df = label_counts_df.sort_values(by='Predicted_Label')\n",
    "\n",
    "# 显示排序后的结果\n",
    "print(sorted_label_counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f2e70c-58df-4562-a066-284c897ecc35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xh",
   "language": "python",
   "name": "xh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
