{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f75c0c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Geokg\\.conda\\envs\\xh\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib_inline import backend_inline\n",
    "backend_inline.set_matplotlib_formats('svg') # 展示高清图，在 Jupyter Notebook 中设置 matplotlib 图形的输出格式为 SVG 格式\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from scipy.signal import savgol_filter\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split as TTS\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import random_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, confusion_matrix, classification_report\n",
    "\n",
    "import random\n",
    "seed = 0\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0627e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7147, 4766)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 检测系统是否支持 CUDA，即是否有 NVIDIA GPU 可用\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# 加载数据\n",
    "data = pd.read_csv(r\"D:\\向航\\Jupyter_project\\02_HSNI data classification\\Final_Model\\data_cz_test_ANN\\data_33_lithology_train_33+1(85).csv\",encoding='utf-8') #encoding='GBK',防止中文乱码\n",
    "\n",
    "# 数据预处理\n",
    "X_origin = data.iloc[:,1:-1]\n",
    "y_origin = data.iloc[:,-1]\n",
    "X_SG = savgol_filter(X_origin, 5, 2)\n",
    "Label = LabelEncoder().fit_transform(y_origin)\n",
    "data.iloc[:,1:-1] = X_SG\n",
    "data.iloc[:, -1] = Label\n",
    "X = data.iloc[:,1:-1]\n",
    "y = data.iloc[:,-1]\n",
    "X.shape, y.shape\n",
    "\n",
    "# 降维\n",
    "X_dr = PCA(29).fit_transform(X)\n",
    "\n",
    "# 转换为 torch 中的张量格式\n",
    "X_tensor = torch.tensor(X_dr, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "# 将数据移动到GPU\n",
    "X_tensor = X_tensor.to(device)\n",
    "y_tensor = y_tensor.to(device)\n",
    "\n",
    "Xtrain, Xtest, Ytrain, Ytest = TTS(X_dr,y,test_size=0.4,random_state=0)\n",
    "\n",
    "# 转换为 torch 中的张量格式\n",
    "X_train_tensor = torch.tensor(Xtrain, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(Xtest, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(Ytrain, dtype=torch.long)\n",
    "y_test_array = Ytest.values\n",
    "y_test_tensor = torch.tensor(y_test_array, dtype=torch.long)\n",
    "\n",
    "# 将数据移动到GPU\n",
    "X_train_tensor = X_train_tensor.to(device)\n",
    "X_test_tensor = X_test_tensor.to(device)\n",
    "y_train_tensor = y_train_tensor.to(device)\n",
    "y_test_tensor = y_test_tensor.to(device)\n",
    "\n",
    "# 创建训练集和测试集的 TensorDataset\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# 创建 DataLoader 对象\n",
    "# train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "# test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "train_size = len(train_dataset)\n",
    "test_size = len(test_dataset)\n",
    "\n",
    "train_size, test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad90ce99-0297-4125-ba84-9d2a3a476b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Original_Label  Encoded_Label\n",
      "0          01_辉绿岩              0\n",
      "1          02_斜长岩              1\n",
      "2          03_正长岩              2\n",
      "3        05_辉石闪长岩              3\n",
      "4         07_花岗斑岩              4\n",
      "5          09_橄榄岩              5\n",
      "6         10_闪长玢岩              6\n",
      "7        11_粗粒花岗岩              7\n",
      "8        12_斑状花岗岩              8\n",
      "9        13_斜长花岗岩              9\n",
      "10       17_角砾凝灰岩             10\n",
      "11        26_紫色页岩             11\n",
      "12        28_炭质页岩             12\n",
      "13        31_泥质灰岩             13\n",
      "14       33_泥晶石灰岩             14\n",
      "15        37_石英砾岩             15\n",
      "16       38_复成份砾岩             16\n",
      "17        41_石英砂岩             17\n",
      "18         42_细砂岩             18\n",
      "19      43_高岭石粘土岩             19\n",
      "20      44_蒙脱石粘土岩             20\n",
      "21      45_伊利石粘土岩             21\n",
      "22        49_石英岩②             22\n",
      "23         51_云英岩             23\n",
      "24       55_粗晶大理岩             24\n",
      "25       56_雪白大理岩             25\n",
      "26       58_花岗片麻岩             26\n",
      "27       59_绿泥石片岩             27\n",
      "28     60_含榴白云母片岩             28\n",
      "29      63_云母石英片岩             29\n",
      "30       64_十字石片岩             30\n",
      "31         66_蛇纹岩             31\n",
      "32     67_石榴子石矽卡岩             32\n",
      "33         68_花岗岩             33\n"
     ]
    }
   ],
   "source": [
    "# 初始化 LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# 对原始标签进行拟合\n",
    "label_encoder.fit(y_origin)\n",
    "\n",
    "# 创建一个 DataFrame 来展示原始标签与转换后标签的对应关系\n",
    "label_mapping_df = pd.DataFrame({\n",
    "    'Original_Label': label_encoder.classes_,\n",
    "    'Encoded_Label': label_encoder.transform(label_encoder.classes_)\n",
    "})\n",
    "\n",
    "# 显示表格\n",
    "print(label_mapping_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e832a0c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNN(\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=29, out_features=170, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.16, inplace=False)\n",
       "    (3): Linear(in_features=170, out_features=241, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.16, inplace=False)\n",
       "    (6): Linear(in_features=241, out_features=97, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Dropout(p=0.16, inplace=False)\n",
       "    (9): Linear(in_features=97, out_features=177, bias=True)\n",
       "    (10): ReLU()\n",
       "    (11): Dropout(p=0.16, inplace=False)\n",
       "    (12): Linear(in_features=177, out_features=164, bias=True)\n",
       "    (13): ReLU()\n",
       "    (14): Dropout(p=0.16, inplace=False)\n",
       "    (15): Linear(in_features=164, out_features=34, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 搭建网络\n",
    "class DNN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes, hidden_layer_sizes, dropout_prob):\n",
    "        ''' 搭建神经网络各层 '''\n",
    "        super(DNN, self).__init__()\n",
    "\n",
    "        self.hidden_layer_sizes = hidden_layer_sizes  # 调整隐藏层尺寸\n",
    "        self.dropout_prob = dropout_prob  # 调整 dropout 概率\n",
    "\n",
    "        layers = []\n",
    "        prev_layer_size = input_size\n",
    "\n",
    "        for layer_size in self.hidden_layer_sizes:\n",
    "            layers.append(nn.Linear(prev_layer_size, layer_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(self.dropout_prob))\n",
    "            prev_layer_size = layer_size\n",
    "\n",
    "        layers.append(nn.Linear(prev_layer_size, num_classes))\n",
    "\n",
    "        self.net = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ''' 前向传播 '''\n",
    "        y = self.net(x) # x 即输入数据\n",
    "        return y # y 即输出数据\n",
    "\n",
    "# 贝叶斯优化超参数\n",
    "num_classes = 34\n",
    "input_size = X_tensor.shape[1]\n",
    "hidden_layer_sizes = [170, 241, 97, 177, 164]\n",
    "dropout_prob = 0.16\n",
    "\n",
    "# 创建模型实例\n",
    "model = DNN(input_size, num_classes, hidden_layer_sizes, dropout_prob)\n",
    "model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1fed73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100] - Loss: 2.0747, Cumulative Avg Loss: 2.0747, Accuracy: 0.3189\n",
      "Epoch [2/100] - Loss: 0.7316, Cumulative Avg Loss: 1.4031, Accuracy: 0.7353\n",
      "Epoch [3/100] - Loss: 0.4180, Cumulative Avg Loss: 1.0747, Accuracy: 0.8515\n",
      "Epoch [4/100] - Loss: 0.2828, Cumulative Avg Loss: 0.8768, Accuracy: 0.9032\n",
      "Epoch [5/100] - Loss: 0.1807, Cumulative Avg Loss: 0.7375, Accuracy: 0.9386\n",
      "Epoch [6/100] - Loss: 0.1822, Cumulative Avg Loss: 0.6450, Accuracy: 0.9439\n",
      "Epoch [7/100] - Loss: 0.1489, Cumulative Avg Loss: 0.5741, Accuracy: 0.9521\n",
      "Epoch [8/100] - Loss: 0.1222, Cumulative Avg Loss: 0.5176, Accuracy: 0.9639\n",
      "Epoch [9/100] - Loss: 0.0951, Cumulative Avg Loss: 0.4707, Accuracy: 0.9709\n",
      "Epoch [10/100] - Loss: 0.0858, Cumulative Avg Loss: 0.4322, Accuracy: 0.9769\n",
      "Epoch [11/100] - Loss: 0.1023, Cumulative Avg Loss: 0.4022, Accuracy: 0.9696\n",
      "Epoch [12/100] - Loss: 0.0870, Cumulative Avg Loss: 0.3759, Accuracy: 0.9761\n",
      "Epoch [13/100] - Loss: 0.0627, Cumulative Avg Loss: 0.3518, Accuracy: 0.9800\n",
      "Epoch [14/100] - Loss: 0.0415, Cumulative Avg Loss: 0.3297, Accuracy: 0.9875\n",
      "Epoch [15/100] - Loss: 0.1172, Cumulative Avg Loss: 0.3155, Accuracy: 0.9695\n",
      "Epoch [16/100] - Loss: 0.0655, Cumulative Avg Loss: 0.2999, Accuracy: 0.9811\n",
      "Epoch [17/100] - Loss: 0.0584, Cumulative Avg Loss: 0.2857, Accuracy: 0.9859\n",
      "Epoch [18/100] - Loss: 0.0560, Cumulative Avg Loss: 0.2729, Accuracy: 0.9861\n",
      "Epoch [19/100] - Loss: 0.0531, Cumulative Avg Loss: 0.2614, Accuracy: 0.9863\n",
      "Epoch [20/100] - Loss: 0.0518, Cumulative Avg Loss: 0.2509, Accuracy: 0.9850\n",
      "Epoch [21/100] - Loss: 0.0436, Cumulative Avg Loss: 0.2410, Accuracy: 0.9870\n",
      "Epoch [22/100] - Loss: 0.0462, Cumulative Avg Loss: 0.2321, Accuracy: 0.9854\n",
      "Epoch [23/100] - Loss: 0.0580, Cumulative Avg Loss: 0.2246, Accuracy: 0.9854\n",
      "Epoch [24/100] - Loss: 0.0413, Cumulative Avg Loss: 0.2169, Accuracy: 0.9895\n",
      "Epoch [25/100] - Loss: 0.0486, Cumulative Avg Loss: 0.2102, Accuracy: 0.9867\n",
      "Epoch [26/100] - Loss: 0.0465, Cumulative Avg Loss: 0.2039, Accuracy: 0.9868\n",
      "Epoch [27/100] - Loss: 0.0464, Cumulative Avg Loss: 0.1981, Accuracy: 0.9856\n",
      "Epoch [28/100] - Loss: 0.0457, Cumulative Avg Loss: 0.1926, Accuracy: 0.9888\n",
      "Epoch [29/100] - Loss: 0.0715, Cumulative Avg Loss: 0.1885, Accuracy: 0.9827\n",
      "Epoch [30/100] - Loss: 0.0558, Cumulative Avg Loss: 0.1840, Accuracy: 0.9882\n",
      "Epoch [31/100] - Loss: 0.0615, Cumulative Avg Loss: 0.1801, Accuracy: 0.9839\n",
      "Epoch [32/100] - Loss: 0.0319, Cumulative Avg Loss: 0.1754, Accuracy: 0.9920\n",
      "Epoch [33/100] - Loss: 0.0454, Cumulative Avg Loss: 0.1715, Accuracy: 0.9878\n",
      "Epoch [34/100] - Loss: 0.0420, Cumulative Avg Loss: 0.1677, Accuracy: 0.9898\n",
      "Epoch [35/100] - Loss: 0.0405, Cumulative Avg Loss: 0.1641, Accuracy: 0.9903\n",
      "Epoch [36/100] - Loss: 0.0336, Cumulative Avg Loss: 0.1604, Accuracy: 0.9906\n",
      "Epoch [37/100] - Loss: 0.0358, Cumulative Avg Loss: 0.1571, Accuracy: 0.9912\n",
      "Epoch [38/100] - Loss: 0.0144, Cumulative Avg Loss: 0.1533, Accuracy: 0.9955\n",
      "Epoch [39/100] - Loss: 0.0239, Cumulative Avg Loss: 0.1500, Accuracy: 0.9933\n",
      "Epoch [40/100] - Loss: 0.0741, Cumulative Avg Loss: 0.1481, Accuracy: 0.9867\n",
      "Epoch [41/100] - Loss: 0.0514, Cumulative Avg Loss: 0.1457, Accuracy: 0.9887\n",
      "Epoch [42/100] - Loss: 0.0208, Cumulative Avg Loss: 0.1428, Accuracy: 0.9940\n",
      "Epoch [43/100] - Loss: 0.0425, Cumulative Avg Loss: 0.1404, Accuracy: 0.9902\n",
      "Epoch [44/100] - Loss: 0.0317, Cumulative Avg Loss: 0.1380, Accuracy: 0.9930\n",
      "Epoch [45/100] - Loss: 0.0750, Cumulative Avg Loss: 0.1366, Accuracy: 0.9842\n",
      "Epoch [46/100] - Loss: 0.0375, Cumulative Avg Loss: 0.1344, Accuracy: 0.9913\n",
      "Epoch [47/100] - Loss: 0.0268, Cumulative Avg Loss: 0.1321, Accuracy: 0.9938\n",
      "Epoch [48/100] - Loss: 0.0355, Cumulative Avg Loss: 0.1301, Accuracy: 0.9917\n",
      "Epoch [49/100] - Loss: 0.0309, Cumulative Avg Loss: 0.1281, Accuracy: 0.9919\n",
      "Epoch [50/100] - Loss: 0.0283, Cumulative Avg Loss: 0.1261, Accuracy: 0.9923\n",
      "Epoch [51/100] - Loss: 0.0228, Cumulative Avg Loss: 0.1241, Accuracy: 0.9948\n",
      "Epoch [52/100] - Loss: 0.0384, Cumulative Avg Loss: 0.1224, Accuracy: 0.9901\n",
      "Epoch [53/100] - Loss: 0.0296, Cumulative Avg Loss: 0.1207, Accuracy: 0.9919\n",
      "Epoch [54/100] - Loss: 0.0207, Cumulative Avg Loss: 0.1188, Accuracy: 0.9957\n",
      "Epoch [55/100] - Loss: 0.0136, Cumulative Avg Loss: 0.1169, Accuracy: 0.9966\n",
      "Epoch [56/100] - Loss: 0.0205, Cumulative Avg Loss: 0.1152, Accuracy: 0.9957\n",
      "Epoch [57/100] - Loss: 0.0104, Cumulative Avg Loss: 0.1133, Accuracy: 0.9969\n",
      "Epoch [58/100] - Loss: 0.0146, Cumulative Avg Loss: 0.1116, Accuracy: 0.9959\n",
      "Epoch [59/100] - Loss: 0.0580, Cumulative Avg Loss: 0.1107, Accuracy: 0.9874\n",
      "Epoch [60/100] - Loss: 0.0696, Cumulative Avg Loss: 0.1100, Accuracy: 0.9859\n",
      "Epoch [61/100] - Loss: 0.0454, Cumulative Avg Loss: 0.1090, Accuracy: 0.9909\n",
      "Epoch [62/100] - Loss: 0.0272, Cumulative Avg Loss: 0.1077, Accuracy: 0.9929\n",
      "Epoch [63/100] - Loss: 0.1019, Cumulative Avg Loss: 0.1076, Accuracy: 0.9804\n",
      "Epoch [64/100] - Loss: 0.0441, Cumulative Avg Loss: 0.1066, Accuracy: 0.9905\n",
      "Epoch [65/100] - Loss: 0.0260, Cumulative Avg Loss: 0.1053, Accuracy: 0.9951\n",
      "Epoch [66/100] - Loss: 0.0514, Cumulative Avg Loss: 0.1045, Accuracy: 0.9892\n",
      "Epoch [67/100] - Loss: 0.0205, Cumulative Avg Loss: 0.1033, Accuracy: 0.9950\n",
      "Epoch [68/100] - Loss: 0.0328, Cumulative Avg Loss: 0.1022, Accuracy: 0.9919\n",
      "Epoch [69/100] - Loss: 0.0282, Cumulative Avg Loss: 0.1012, Accuracy: 0.9936\n",
      "Epoch [70/100] - Loss: 0.0179, Cumulative Avg Loss: 0.1000, Accuracy: 0.9962\n",
      "Epoch [71/100] - Loss: 0.0401, Cumulative Avg Loss: 0.0991, Accuracy: 0.9929\n",
      "Epoch [72/100] - Loss: 0.0453, Cumulative Avg Loss: 0.0984, Accuracy: 0.9913\n",
      "Epoch [73/100] - Loss: 0.0224, Cumulative Avg Loss: 0.0973, Accuracy: 0.9938\n",
      "Epoch [74/100] - Loss: 0.0087, Cumulative Avg Loss: 0.0961, Accuracy: 0.9972\n",
      "Epoch [75/100] - Loss: 0.0146, Cumulative Avg Loss: 0.0951, Accuracy: 0.9966\n",
      "Epoch [76/100] - Loss: 0.0141, Cumulative Avg Loss: 0.0940, Accuracy: 0.9968\n",
      "Epoch [77/100] - Loss: 0.0298, Cumulative Avg Loss: 0.0932, Accuracy: 0.9933\n",
      "Epoch [78/100] - Loss: 0.0199, Cumulative Avg Loss: 0.0922, Accuracy: 0.9950\n",
      "Epoch [79/100] - Loss: 0.0333, Cumulative Avg Loss: 0.0915, Accuracy: 0.9924\n",
      "Epoch [80/100] - Loss: 0.0178, Cumulative Avg Loss: 0.0906, Accuracy: 0.9959\n",
      "Epoch [81/100] - Loss: 0.0250, Cumulative Avg Loss: 0.0897, Accuracy: 0.9969\n",
      "Epoch [82/100] - Loss: 0.0242, Cumulative Avg Loss: 0.0889, Accuracy: 0.9937\n",
      "Epoch [83/100] - Loss: 0.0304, Cumulative Avg Loss: 0.0882, Accuracy: 0.9923\n",
      "Epoch [84/100] - Loss: 0.0185, Cumulative Avg Loss: 0.0874, Accuracy: 0.9958\n",
      "Epoch [85/100] - Loss: 0.0161, Cumulative Avg Loss: 0.0866, Accuracy: 0.9962\n",
      "Epoch [86/100] - Loss: 0.0235, Cumulative Avg Loss: 0.0858, Accuracy: 0.9948\n",
      "Epoch [87/100] - Loss: 0.0378, Cumulative Avg Loss: 0.0853, Accuracy: 0.9936\n",
      "Epoch [88/100] - Loss: 0.0622, Cumulative Avg Loss: 0.0850, Accuracy: 0.9887\n",
      "Epoch [89/100] - Loss: 0.0623, Cumulative Avg Loss: 0.0848, Accuracy: 0.9896\n",
      "Epoch [90/100] - Loss: 0.0495, Cumulative Avg Loss: 0.0844, Accuracy: 0.9916\n",
      "Epoch [91/100] - Loss: 0.0260, Cumulative Avg Loss: 0.0837, Accuracy: 0.9931\n",
      "Epoch [92/100] - Loss: 0.0512, Cumulative Avg Loss: 0.0834, Accuracy: 0.9952\n",
      "Epoch [93/100] - Loss: 0.0311, Cumulative Avg Loss: 0.0828, Accuracy: 0.9936\n",
      "Epoch [94/100] - Loss: 0.0267, Cumulative Avg Loss: 0.0822, Accuracy: 0.9938\n",
      "Epoch [95/100] - Loss: 0.0158, Cumulative Avg Loss: 0.0815, Accuracy: 0.9964\n",
      "Epoch [96/100] - Loss: 0.0266, Cumulative Avg Loss: 0.0809, Accuracy: 0.9966\n",
      "Epoch [97/100] - Loss: 0.0306, Cumulative Avg Loss: 0.0804, Accuracy: 0.9944\n",
      "Epoch [98/100] - Loss: 0.0136, Cumulative Avg Loss: 0.0797, Accuracy: 0.9971\n",
      "Epoch [99/100] - Loss: 0.0396, Cumulative Avg Loss: 0.0793, Accuracy: 0.9919\n",
      "Epoch [100/100] - Loss: 0.0368, Cumulative Avg Loss: 0.0789, Accuracy: 0.9943\n"
     ]
    }
   ],
   "source": [
    "# 训练\n",
    "loss_fn = nn.CrossEntropyLoss(reduction='mean') # 对所有样本的损失求平均，得到一个标量\n",
    "learning_rate = 0.0028690154931344\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 100\n",
    "accuracies = [] # 记录准确率变化的列表\n",
    "losses = [] # 记录损失函数变化的列表\n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    batch_loss = 0\n",
    "    \n",
    "    for (x, y) in train_dataloader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        Pred = model(x)\n",
    "        _, Pred_classes = torch.max(Pred, dim=1)\n",
    "        total_correct += torch.sum(Pred_classes == y)\n",
    "        total_samples += y.size(0)\n",
    "        loss = loss_fn(Pred, y)\n",
    "        batch_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    epoch_loss = batch_loss / len(train_dataloader)\n",
    "    epoch_accuracy = total_correct / total_samples\n",
    "    accuracies.append(epoch_accuracy.item())\n",
    "    losses.append(epoch_loss)\n",
    "\n",
    "    # 打印当前 epoch 的损失和累计平均损失\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] - Loss: {epoch_loss:.4f}, Cumulative Avg Loss: {sum(losses)/(epoch+1):.4f}, Accuracy: {epoch_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22b8d655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9990, device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试\n",
    "correct = 0\n",
    "total = 0\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad(): # 该局部关闭梯度计算功能\n",
    "    for (x, y) in test_dataloader: # 获取小批次的 x 与 y\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        Pred = model(x) # 一次前向传播（小批量）\n",
    "        _, Pred_classes = torch.max(Pred, dim=1)  # 找到最大概率对应的类别索引\n",
    "        correct += torch.sum(Pred_classes == y)  # 计算正确的个数\n",
    "        all_preds.extend(Pred_classes.cpu().numpy())  # 将预测转换为NumPy数组并存储\n",
    "        all_labels.extend(y.cpu().numpy())  # 将真实标签转换为NumPy数组并存储\n",
    "        total += y.size(0)\n",
    "accuracy = correct/total\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02a1ff2b-27ad-4e5e-b6ec-2afaf55abc91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    precision    recall  f1-score  support\n",
      "0    1.000000  1.000000  1.000000    159.0\n",
      "1    1.000000  1.000000  1.000000    154.0\n",
      "2    0.993631  1.000000  0.996805    156.0\n",
      "3    1.000000  1.000000  1.000000    116.0\n",
      "4    1.000000  1.000000  1.000000    156.0\n",
      "5    1.000000  1.000000  1.000000    169.0\n",
      "6    1.000000  1.000000  1.000000    156.0\n",
      "7    1.000000  1.000000  1.000000    160.0\n",
      "8    0.986577  1.000000  0.993243    147.0\n",
      "9    1.000000  1.000000  1.000000    159.0\n",
      "10   1.000000  0.988571  0.994253    175.0\n",
      "11   0.994012  1.000000  0.996997    166.0\n",
      "12   1.000000  1.000000  1.000000    115.0\n",
      "13   1.000000  1.000000  1.000000    154.0\n",
      "14   1.000000  1.000000  1.000000    156.0\n",
      "15   1.000000  1.000000  1.000000     71.0\n",
      "16   1.000000  1.000000  1.000000     76.0\n",
      "17   1.000000  1.000000  1.000000    110.0\n",
      "18   1.000000  1.000000  1.000000    123.0\n",
      "19   1.000000  1.000000  1.000000    177.0\n",
      "20   1.000000  1.000000  1.000000    174.0\n",
      "21   1.000000  1.000000  1.000000    161.0\n",
      "22   1.000000  1.000000  1.000000    122.0\n",
      "23   1.000000  1.000000  1.000000    163.0\n",
      "24   0.994350  1.000000  0.997167    176.0\n",
      "25   1.000000  0.994186  0.997085    172.0\n",
      "26   1.000000  0.993939  0.996960    165.0\n",
      "27   1.000000  1.000000  1.000000    124.0\n",
      "28   1.000000  1.000000  1.000000    125.0\n",
      "29   1.000000  1.000000  1.000000    119.0\n",
      "30   1.000000  1.000000  1.000000    115.0\n",
      "31   1.000000  1.000000  1.000000    111.0\n",
      "32   1.000000  1.000000  1.000000    148.0\n",
      "33   1.000000  0.972222  0.985915     36.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "\n",
    "# 假设 all_labels_2 和 all_preds_2 分别是真实标签和预测标签的列表\n",
    "report = classification_report(all_labels, all_preds, output_dict=True)\n",
    "\n",
    "# 将报告转换为 Pandas DataFrame\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "\n",
    "# 删除总结行（如果不需要的话）\n",
    "report_df = report_df.drop(['accuracy', 'macro avg', 'weighted avg'])\n",
    "\n",
    "print(report_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "432a4423-4b17-44a7-a8f3-142d1e6566c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "标签 33 被错误预测为标签 2 的数量: 1\n",
      "标签 33 正确预测的数量: 35\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# 生成混淆矩阵\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# 提取标签 33 的混淆矩阵行\n",
    "label_33_row = cm[33]\n",
    "\n",
    "# 输出标签 33 的所有预测情况\n",
    "for label, count in enumerate(label_33_row):\n",
    "    if label == 33:\n",
    "        print(f\"标签 33 正确预测的数量: {count}\")\n",
    "    elif count > 0:\n",
    "        print(f\"标签 33 被错误预测为标签 {label} 的数量: {count}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16df62c-f71e-4e20-8117-8a847f18e1a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xh",
   "language": "python",
   "name": "xh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
